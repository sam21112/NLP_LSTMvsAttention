{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2-I7PacDTzN"
      },
      "source": [
        "# Improting Libraries & Data Preperation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "222dug5Zl20K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcFVhSMFBkuP",
        "outputId": "3cadd468-2095-4ec8-f2af-6099fb624a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.9/dist-packages (from scikeras) (23.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os51kTCS9lLn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as  pd\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras as k\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional,Concatenate\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import Adamax, Adam\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.layers import TimeDistributed\n",
        "%matplotlib inline\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT1-NL3LOxXs"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1-JOcWbDbqt"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/NLP/aggregated7c.csv',sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxQIetJQDnsu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0f948c85-e113-4a1b-cf74-57d96b8584ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Polarity                                            cleaned  Length  \\\n",
              "0         1  this sound track was beautiful it paints the s...    75.0   \n",
              "1         1  i am reading a lot of reviews saying that this...    94.0   \n",
              "2         1  this soundtrack is my favorite music of all ti...   129.0   \n",
              "3         1  i truly like this soundtrack and i enjoy video...   115.0   \n",
              "4         1  if you have played the game you know how divin...    79.0   \n",
              "\n",
              "                  source  \n",
              "0  twitter-train_cleaned  \n",
              "1  twitter-train_cleaned  \n",
              "2  twitter-train_cleaned  \n",
              "3  twitter-train_cleaned  \n",
              "4  twitter-train_cleaned  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54d480d0-b2d0-4ce8-9453-4ce86fda4c0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Polarity</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>Length</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>this sound track was beautiful it paints the s...</td>\n",
              "      <td>75.0</td>\n",
              "      <td>twitter-train_cleaned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>i am reading a lot of reviews saying that this...</td>\n",
              "      <td>94.0</td>\n",
              "      <td>twitter-train_cleaned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>this soundtrack is my favorite music of all ti...</td>\n",
              "      <td>129.0</td>\n",
              "      <td>twitter-train_cleaned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>i truly like this soundtrack and i enjoy video...</td>\n",
              "      <td>115.0</td>\n",
              "      <td>twitter-train_cleaned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>if you have played the game you know how divin...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>twitter-train_cleaned</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54d480d0-b2d0-4ce8-9453-4ce86fda4c0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54d480d0-b2d0-4ce8-9453-4ce86fda4c0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54d480d0-b2d0-4ce8-9453-4ce86fda4c0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq1KtENvO_cK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33900d0-1ae2-44de-ef3c-e0ccbdc22ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows: 7334528\n",
            "Number of columns: 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7334528, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data = data.sample(frac=1,random_state=6400).reset_index(drop=True)\n",
        "print(\"Number of Rows:\", data.shape[0])\n",
        "print(\"Number of columns:\", data.shape[1])\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdulssuJPKv2"
      },
      "outputs": [],
      "source": [
        "data.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(frac=1,random_state=6400).reset_index(drop=True)\n",
        "print(\"Number of Rows after dropping null:\", data.shape[0])\n",
        "print(\"Number of columns after dropping null:\", data.shape[1])\n",
        "data.shape"
      ],
      "metadata": {
        "id": "nXY7uf7dxW_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a685bcc-6098-467e-b0af-dd86d77d8a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rows after dropping null: 7333767\n",
            "Number of columns after dropping null: 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7333767, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6_l8y1SPQzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2334bbd1-a7eb-49a8-ed72-d1ed1e5fd768"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Polarity    0\n",
              "cleaned     0\n",
              "Length      0\n",
              "source      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aXWNlexPTJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "51b860a8-162d-4168-9e10-624bdaf45260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Polarity        Length\n",
              "count  6.953027e+06  6.953027e+06\n",
              "mean   5.784942e-01  4.503879e+01\n",
              "std    4.938003e-01  3.832743e+01\n",
              "min    0.000000e+00  1.000000e+00\n",
              "25%    0.000000e+00  1.500000e+01\n",
              "50%    1.000000e+00  3.100000e+01\n",
              "75%    1.000000e+00  6.900000e+01\n",
              "max    1.000000e+00  1.500000e+02"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee6b3981-3b8f-4c17-9a2f-567ac7fae83d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.953027e+06</td>\n",
              "      <td>6.953027e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.784942e-01</td>\n",
              "      <td>4.503879e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.938003e-01</td>\n",
              "      <td>3.832743e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.500000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.100000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>6.900000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.500000e+02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee6b3981-3b8f-4c17-9a2f-567ac7fae83d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee6b3981-3b8f-4c17-9a2f-567ac7fae83d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee6b3981-3b8f-4c17-9a2f-567ac7fae83d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Selecting only data with less than 150 word length\n",
        "data=data[data['Length']<=150]\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mR6np4WgtXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "bc4b71c8-d54a-454d-bca2-45a847ea13f8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plotting number of data points per group\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "lengths=data.Length\n",
        "# Creating histogram\n",
        "fig, ax = plt.subplots(figsize =(10, 6))\n",
        "w = 25\n",
        "ax.hist(lengths, edgecolor='black', bins=np.arange(min(lengths), max(lengths) + w, w))\n",
        "plt.xlim(xmin=0, xmax = 150)\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxCiSLcRqo2K"
      },
      "outputs": [],
      "source": [
        "group10=data[(data['Length']<=20)&(data['Length']>0)&(data['Polarity']==0)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group20=data[(data['Length']<=40)&(data['Length']>20)&(data['Polarity']==0)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group30=data[(data['Length']<=60)&(data['Length']>40)&(data['Polarity']==0)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group40=data[(data['Length']<=80)&(data['Length']>60)&(data['Polarity']==0)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group50=data[(data['Length']<=100)&(data['Length']>80)&(data['Polarity']==0)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group60=data[(data['Length']>100)&(data['Polarity']==0)].sample(225000,ignore_index=True,random_state=6400)\n",
        "\n",
        "group11=data[(data['Length']<=20)&(data['Length']>0)&(data['Polarity']==1)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group21=data[(data['Length']<=40)&(data['Length']>20)&(data['Polarity']==1)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group31=data[(data['Length']<=60)&(data['Length']>40)&(data['Polarity']==1)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group41=data[(data['Length']<=80)&(data['Length']>60)&(data['Polarity']==1)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group51=data[(data['Length']<=100)&(data['Length']>80)&(data['Polarity']==1)].sample(225000,ignore_index=True,random_state=6400)\n",
        "group61=data[(data['Length']>100)&(data['Polarity']==1)].sample(225000,ignore_index=True,random_state=6400)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "group1=pd.concat([group10,group11],axis=0)\n",
        "group2=pd.concat([group20,group21],axis=0)\n",
        "group3=pd.concat([group30,group31],axis=0)\n",
        "group4=pd.concat([group40,group41],axis=0)\n",
        "group5=pd.concat([group50,group51],axis=0)\n",
        "group6=pd.concat([group60,group61],axis=0)"
      ],
      "metadata": {
        "id": "ovEtV3AkT-R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train,x1_test,y1_train,y1_test=train_test_split(group1['cleaned'],group1['Polarity'],test_size=0.1,random_state=6400)\n",
        "x2_train,x2_test,y2_train,y2_test=train_test_split(group2['cleaned'],group2['Polarity'],test_size=0.1,random_state=6400)\n",
        "x3_train,x3_test,y3_train,y3_test=train_test_split(group3['cleaned'],group3['Polarity'],test_size=0.1,random_state=6400)\n",
        "x4_train,x4_test,y4_train,y4_test=train_test_split(group4['cleaned'],group4['Polarity'],test_size=0.1,random_state=6400)\n",
        "x5_train,x5_test,y5_train,y5_test=train_test_split(group5['cleaned'],group5['Polarity'],test_size=0.1,random_state=6400)\n",
        "\n",
        "x_train=pd.concat([x1_train,x2_train,x3_train,x4_train,x5_train],axis=0)\n",
        "y_train=pd.concat([y1_train,y2_train,y3_train,y4_train,y5_train],axis=0)\n",
        "x_test=pd.concat([x1_test,x2_test,x3_test,x4_test,x5_test],axis=0)\n",
        "y_test=pd.concat([y1_test,y2_test,y3_test,y4_test,y5_test],axis=0)\n",
        "\n",
        "max_len=100\n",
        "max_word=20000"
      ],
      "metadata": {
        "id": "TW2LxTY3UVpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZhUlMHZxiAd"
      },
      "source": [
        "## Tokenizing words and splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGpRqheEvGwT"
      },
      "outputs": [],
      "source": [
        "max_len  = 100 #Depending on the group\n",
        "max_word = 20000\n",
        "\n",
        "# tokenizer = Tokenizer(num_words=20000,filters='\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "# tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "tokenizer_file = '/content/drive/MyDrive/NLP/tokenizer.pkl'\n",
        "with open(tokenizer_file, 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "import keras\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "# convert Train dataset to sequence and pad sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_len)\n",
        "\n",
        "# convert Test dataset to sequence and pad sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arrixOPTA9zJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd30c3f8-bba8-4764-b92d-fdc86060dbd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum number of words: 0\n",
            "median number of words: 47.0\n",
            "average number of words: 46.91495209876543\n",
            "maximum number of words: 100\n"
          ]
        }
      ],
      "source": [
        "l = [len(i) for i in train_sequences]\n",
        "l = np.array(l)\n",
        "print('minimum number of words: {}'.format(l.min()))\n",
        "print('median number of words: {}'.format(np.median(l)))\n",
        "print('average number of words: {}'.format(l.mean()))\n",
        "print('maximum number of words: {}'.format(l.max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiQNdXcs-0YG"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TplRzOGDEAri"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1UlDWqPl36",
        "outputId": "11571c63-6065-4178-9314-9c3531f0e64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.9/dist-packages (from scikeras) (23.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    'num_lstm_layers': [1, 2, 3],\n",
        "    'num_lstm_units': [32, 64, 128],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4]\n",
        "}\n",
        "\n",
        "param_grid = list(ParameterGrid(hyperparameters))"
      ],
      "metadata": {
        "id": "r6rRPokj45EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_lstm_layers, num_lstm_units, learning_rate, dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000, 128, input_length=max_len))\n",
        "    model.add(LSTM(num_lstm_units, return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Xgs-ZTPhcIga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search\n",
        "best_params = None\n",
        "best_score = 0\n",
        "for params in param_grid:\n",
        "    model = create_model(**params)\n",
        "    model.fit(train_padded, y_train,batch_size=128,epochs=10, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=10)],steps_per_epoch=2048)\n",
        "    loss, score = model.evaluate(test_padded, y_test)\n",
        "    print(f\"params: {params}, score: {score}\")\n",
        "\n",
        "    # Save best hyperparameters\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_params = params"
      ],
      "metadata": {
        "id": "P6iRBXZumZ5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "hIwTPsyM7s1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b733de5-2c50-4239-a159-90374774ff3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters\n",
            "{'dropout_rate': 0.3, 'learning_rate': 0.001, 'num_lstm_layers': 2, 'num_lstm_units': 128}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000, 128, input_length=max_len))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "2WRI13mHmvV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model on combined training and validation set with best hyperparameters\n",
        "model = lstm_model()\n",
        "model.summary()\n",
        "model.fit(train_padded, y_train ,batch_size=128,epochs=1000, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=15)],steps_per_epoch=2048)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocW8o41ODrr8",
        "outputId": "44145a7d-d190-4c09-95be-ad18f3388b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          2560000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 128)          131584    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 128)          0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 100, 128)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 128)          131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100, 128)          0         \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 100, 128)          0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100, 1)            129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,823,297\n",
            "Trainable params: 2,823,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "2048/2048 [==============================] - 119s 54ms/step - loss: 0.4343 - accuracy: 0.7920 - val_loss: 0.3886 - val_accuracy: 0.8156\n",
            "Epoch 2/1000\n",
            "2048/2048 [==============================] - 53s 26ms/step - loss: 0.3793 - accuracy: 0.8240 - val_loss: 0.3758 - val_accuracy: 0.8308\n",
            "Epoch 3/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.3612 - accuracy: 0.8334 - val_loss: 0.3533 - val_accuracy: 0.8372\n",
            "Epoch 4/1000\n",
            "2048/2048 [==============================] - 50s 24ms/step - loss: 0.3500 - accuracy: 0.8395 - val_loss: 0.3410 - val_accuracy: 0.8433\n",
            "Epoch 5/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.3401 - accuracy: 0.8435 - val_loss: 0.3308 - val_accuracy: 0.8468\n",
            "Epoch 6/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.3319 - accuracy: 0.8486 - val_loss: 0.3304 - val_accuracy: 0.8508\n",
            "Epoch 7/1000\n",
            "2048/2048 [==============================] - 50s 24ms/step - loss: 0.3258 - accuracy: 0.8516 - val_loss: 0.3235 - val_accuracy: 0.8517\n",
            "Epoch 8/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.3132 - accuracy: 0.8586 - val_loss: 0.3183 - val_accuracy: 0.8558\n",
            "Epoch 9/1000\n",
            "2048/2048 [==============================] - 50s 24ms/step - loss: 0.3116 - accuracy: 0.8588 - val_loss: 0.3129 - val_accuracy: 0.8575\n",
            "Epoch 10/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.3094 - accuracy: 0.8597 - val_loss: 0.3114 - val_accuracy: 0.8581\n",
            "Epoch 11/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.3077 - accuracy: 0.8611 - val_loss: 0.3077 - val_accuracy: 0.8612\n",
            "Epoch 12/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.3068 - accuracy: 0.8614 - val_loss: 0.3059 - val_accuracy: 0.8621\n",
            "Epoch 13/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.3045 - accuracy: 0.8620 - val_loss: 0.3053 - val_accuracy: 0.8619\n",
            "Epoch 14/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2961 - accuracy: 0.8665 - val_loss: 0.3046 - val_accuracy: 0.8621\n",
            "Epoch 15/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2861 - accuracy: 0.8721 - val_loss: 0.3070 - val_accuracy: 0.8614\n",
            "Epoch 16/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2877 - accuracy: 0.8708 - val_loss: 0.3021 - val_accuracy: 0.8642\n",
            "Epoch 17/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2874 - accuracy: 0.8710 - val_loss: 0.3032 - val_accuracy: 0.8638\n",
            "Epoch 18/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2894 - accuracy: 0.8701 - val_loss: 0.3026 - val_accuracy: 0.8643\n",
            "Epoch 19/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2895 - accuracy: 0.8702 - val_loss: 0.2993 - val_accuracy: 0.8658\n",
            "Epoch 20/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2884 - accuracy: 0.8702 - val_loss: 0.2971 - val_accuracy: 0.8663\n",
            "Epoch 21/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2754 - accuracy: 0.8768 - val_loss: 0.3012 - val_accuracy: 0.8650\n",
            "Epoch 22/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2700 - accuracy: 0.8794 - val_loss: 0.3039 - val_accuracy: 0.8653\n",
            "Epoch 23/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2702 - accuracy: 0.8795 - val_loss: 0.3019 - val_accuracy: 0.8648\n",
            "Epoch 24/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2736 - accuracy: 0.8776 - val_loss: 0.3018 - val_accuracy: 0.8656\n",
            "Epoch 25/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2725 - accuracy: 0.8784 - val_loss: 0.3034 - val_accuracy: 0.8646\n",
            "Epoch 26/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2759 - accuracy: 0.8768 - val_loss: 0.2979 - val_accuracy: 0.8663\n",
            "Epoch 27/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2762 - accuracy: 0.8765 - val_loss: 0.2969 - val_accuracy: 0.8669\n",
            "Epoch 28/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2541 - accuracy: 0.8873 - val_loss: 0.3050 - val_accuracy: 0.8644\n",
            "Epoch 29/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2533 - accuracy: 0.8870 - val_loss: 0.3100 - val_accuracy: 0.8639\n",
            "Epoch 30/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2574 - accuracy: 0.8856 - val_loss: 0.3057 - val_accuracy: 0.8643\n",
            "Epoch 31/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2593 - accuracy: 0.8843 - val_loss: 0.3070 - val_accuracy: 0.8647\n",
            "Epoch 32/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2617 - accuracy: 0.8829 - val_loss: 0.3018 - val_accuracy: 0.8654\n",
            "Epoch 33/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2640 - accuracy: 0.8821 - val_loss: 0.3050 - val_accuracy: 0.8655\n",
            "Epoch 34/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2607 - accuracy: 0.8842 - val_loss: 0.3150 - val_accuracy: 0.8651\n",
            "Epoch 35/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2382 - accuracy: 0.8945 - val_loss: 0.3163 - val_accuracy: 0.8637\n",
            "Epoch 36/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2394 - accuracy: 0.8938 - val_loss: 0.3156 - val_accuracy: 0.8636\n",
            "Epoch 37/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2443 - accuracy: 0.8915 - val_loss: 0.3156 - val_accuracy: 0.8637\n",
            "Epoch 38/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2470 - accuracy: 0.8907 - val_loss: 0.3137 - val_accuracy: 0.8635\n",
            "Epoch 39/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2480 - accuracy: 0.8898 - val_loss: 0.3153 - val_accuracy: 0.8646\n",
            "Epoch 40/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2515 - accuracy: 0.8883 - val_loss: 0.3105 - val_accuracy: 0.8645\n",
            "Epoch 41/1000\n",
            "2048/2048 [==============================] - 49s 24ms/step - loss: 0.2433 - accuracy: 0.8921 - val_loss: 0.3290 - val_accuracy: 0.8622\n",
            "Epoch 42/1000\n",
            "2048/2048 [==============================] - 48s 24ms/step - loss: 0.2238 - accuracy: 0.9012 - val_loss: 0.3303 - val_accuracy: 0.8617\n",
            "6945/6945 [==============================] - 36s 5ms/step - loss: 0.3303 - accuracy: 0.8617\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9a60d393f6ff>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Evaluate final model on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best hyperparameters: {best_params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation accuracy: {best_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate final model on test set\n",
        "loss, best_score = model.evaluate(test_padded, y_test)\n",
        "print(f\"Validation accuracy: {best_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAdxoGS9jS1n",
        "outputId": "d4799583-de99-4da8-c11a-5d1331f4faa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6945/6945 [==============================] - 36s 5ms/step - loss: 0.3303 - accuracy: 0.8617\n",
            "Validation accuracy: 0.8617249131202698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model and tokenizer"
      ],
      "metadata": {
        "id": "gzWqOfAfbM_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save('LSTM.h5')\n",
        "# save the tokenizer to a file\n",
        "tokenizer_file = '/content/drive/MyDrive/NLP/tokenizer.pkl'\n",
        "with open(tokenizer_file, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "RhHioR07bMiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model and test for each group"
      ],
      "metadata": {
        "id": "wp_F6NW9eObz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100\n",
        "LSTM = tf.keras.models.load_model('/content/drive/MyDrive/NLP/LSTM.h5')\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "LSTM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', get_f1, get_recall, get_precision])\n",
        "LSTM_original = []"
      ],
      "metadata": {
        "id": "K-zA1t28etqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-1\n",
        "\n",
        "g1_test = tokenizer.texts_to_sequences(x1_test)\n",
        "g1_padded = sequence.pad_sequences(g1_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM.evaluate(g1_padded, y1_test)\n",
        "print(\"Group-1\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_original.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrTOnH--eOvl",
        "outputId": "fd000be5-888c-47c7-de9c-96002e274a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 13s 6ms/step - loss: 0.2969 - accuracy: 0.8732 - get_f1: 1.7573 - get_recall: 85.5080 - get_precision: 0.8879\n",
            "Group-1\n",
            "Loss: 0.29693353176116943\n",
            "Accuracy: 0.8732087016105652\n",
            "Recall: 85.50801849365234\n",
            "Precision: 0.887930154800415\n",
            "F1-score: 1.7573148012161255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-2\n",
        "\n",
        "g2_test = tokenizer.texts_to_sequences(x2_test)\n",
        "g2_padded = sequence.pad_sequences(g2_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM.evaluate(g2_padded, y2_test)\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_original.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOt_iEm-kJEH",
        "outputId": "c6221ef5-23f0-467f-d18c-966e99827670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2565 - accuracy: 0.8898 - get_f1: 1.7922 - get_recall: 86.9666 - get_precision: 0.9055\n",
            "Loss: 0.25653859972953796\n",
            "Accuracy: 0.889759361743927\n",
            "Recall: 86.96662139892578\n",
            "Precision: 0.9054985642433167\n",
            "F1-score: 1.7921581268310547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-3\n",
        "\n",
        "g3_test = tokenizer.texts_to_sequences(x3_test)\n",
        "g3_padded = sequence.pad_sequences(g3_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM.evaluate(g3_padded, y3_test)\n",
        "print(\"Group-3\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_original.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22Xc1p2JkK7t",
        "outputId": "76139122-eb66-45ea-89c9-d26a9bb60409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2129 - accuracy: 0.9111 - get_f1: 1.8173 - get_recall: 90.2161 - get_precision: 0.9180\n",
            "Group-3\n",
            "Loss: 0.21290765702724457\n",
            "Accuracy: 0.9111257195472717\n",
            "Recall: 90.21611022949219\n",
            "Precision: 0.9179567098617554\n",
            "F1-score: 1.8173127174377441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-4\n",
        "\n",
        "g4_test = tokenizer.texts_to_sequences(x4_test)\n",
        "g4_padded = sequence.pad_sequences(g4_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM.evaluate(g4_padded, y4_test)\n",
        "print(\"Group-4\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_original.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9EW1bsDkLXA",
        "outputId": "8e381c20-8d81-4d38-d7e8-66c98cf15260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2233 - accuracy: 0.9032 - get_f1: 1.8017 - get_recall: 89.3305 - get_precision: 0.9101\n",
            "Group-4\n",
            "Loss: 0.22333884239196777\n",
            "Accuracy: 0.9032427668571472\n",
            "Recall: 89.3305435180664\n",
            "Precision: 0.9101049900054932\n",
            "F1-score: 1.8017452955245972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-5\n",
        "\n",
        "g5_test = tokenizer.texts_to_sequences(x5_test)\n",
        "g5_padded = sequence.pad_sequences(g5_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM.evaluate(g5_padded, y5_test)\n",
        "print(\"Group-5\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_original.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd1oVwZykMJf",
        "outputId": "4e6d2446-d9c5-4de8-ecda-1d416f372e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.2307 - accuracy: 0.8986 - get_f1: 1.7925 - get_recall: 88.8588 - get_precision: 0.9054\n",
            "Group-5\n",
            "Loss: 0.23070888221263885\n",
            "Accuracy: 0.8985908627510071\n",
            "Recall: 88.85875701904297\n",
            "Precision: 0.9054311513900757\n",
            "F1-score: 1.7924904823303223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Model - With Attention"
      ],
      "metadata": {
        "id": "tlTYv43ZwM82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "TeMa5FA3wUv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    'num_lstm_layers': [1, 2, 3],\n",
        "    'num_lstm_units': [32, 64, 128],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4]\n",
        "}\n",
        "\n",
        "param_grid = list(ParameterGrid(hyperparameters))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "po09dhWguVeK",
        "outputId": "5a574c60-3ea9-4503-97ee-62302545e5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-15324a021ade>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ParameterGrid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class attention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "      super(attention, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
        "    self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")\n",
        "    super(attention, self).build(input_shape)\n",
        "\n",
        "  def call(self, x):\n",
        "    et = tf.keras.backend.dot(x, self.W) + self.b\n",
        "    at = tf.keras.backend.softmax(et, axis=1)\n",
        "    output = x * at\n",
        "    return tf.keras.backend.sum(output, axis=1)\n",
        "\n",
        "  def compute_output_shape(self,input_shape):\n",
        "    return (input_shape[0],input_shape[-1])\n",
        "\n",
        "  def get_config(self):\n",
        "    return super(attention,self).get_config()"
      ],
      "metadata": {
        "id": "gWMh-AOKu_-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(max_len, num_lstm_layers, num_lstm_units, num_dense_units, learning_rate, dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000, 128, input_length=max_len))\n",
        "    for i in range(num_lstm_layers):\n",
        "        model.add(LSTM(num_lstm_units, return_sequences=True)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(attention(max_len))\n",
        "    model.add(Dense(num_dense_units, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "KHgVe-yGBswT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search\n",
        "best_params = None\n",
        "best_score = 0\n",
        "for params in param_grid:\n",
        "    model = create_model(**params)\n",
        "    model.fit(train_padded, y_train,batch_size=128,epochs=10, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=10)],steps_per_epoch=2048)\n",
        "    loss, score = model.evaluate(test_padded, y_test)\n",
        "    print(f\"params: {params}, score: {score}\")\n",
        "\n",
        "    # Save best hyperparameters\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_params = params"
      ],
      "metadata": {
        "id": "fRmpKxNiBsIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "pPAB7gOzB4Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_attention_model():\n",
        "  inputs = Input(shape=(max_len,), dtype=\"int32\")\n",
        "  x = Embedding(20000, 128, input_length=max_len)(inputs)\n",
        "\n",
        "  layer1 = LSTM(128, return_sequences=True)(x)\n",
        "  droupout1 = Dropout(0.3)(layer1)\n",
        "  act1 = Activation('relu')(droupout1)\n",
        "  layer2 = LSTM(128, return_sequences=True)(act1)\n",
        "  dropout2 = Dropout(0.3)(layer2)\n",
        "\n",
        "  att_in = attention()(dropout2)\n",
        "  output1 = Dense(128, activation='relu')(att_in)\n",
        "  dropout3 = Dropout(0.2)(output1)\n",
        "  output2 = Dense(1, activation='sigmoid')(dropout3)\n",
        "\n",
        "  model = tf.keras.Model(inputs, output2)\n",
        "  optimizer = Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "mqRiyyIn60BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lstm_attention_model()\n",
        "model.summary()\n",
        "model.fit(train_padded, y_train ,batch_size=128,epochs=1000, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=15)],steps_per_epoch=2048)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gi1saHk_7lA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate final model on test set\n",
        "loss, best_score = model.evaluate(test_padded, y_test)\n",
        "print(f\"Validation accuracy: {best_score}\")"
      ],
      "metadata": {
        "id": "i0pKyuVhgkrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "jfnHyOnCg3ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save('LSTM_attention.h5')"
      ],
      "metadata": {
        "id": "ef2KKcJmg3le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model and test for each group"
      ],
      "metadata": {
        "id": "JjaGXgMRKjm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100\n",
        "LSTM_att = load_model('/content/drive/MyDrive/NLP/LSTM_attention.h5', custom_objects={\"attention\": attention})\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "LSTM_att.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', get_f1, get_recall, get_precision])\n",
        "LSTM_Att = []"
      ],
      "metadata": {
        "id": "Lnq0oS8EKjm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-1\n",
        "\n",
        "g1_test = tokenizer.texts_to_sequences(x1_test)\n",
        "g1_padded = sequence.pad_sequences(g1_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM_att.evaluate(g1_padded, y1_test)\n",
        "print(\"Group-1\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "K08fsgVQKjm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9679ad2b-6bfa-410d-9471-fa8125716154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 9s 5ms/step - loss: 0.2937 - accuracy: 0.8747 - get_f1: 0.0168 - get_recall: 0.0085 - get_precision: 0.8993\n",
            "Group-1\n",
            "Loss: 0.29368478059768677\n",
            "Accuracy: 0.8747110962867737\n",
            "Recall: 0.008462594822049141\n",
            "Precision: 0.8992683291435242\n",
            "F1-score: 0.016764624044299126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-2\n",
        "\n",
        "g2_test = tokenizer.texts_to_sequences(x2_test)\n",
        "g2_padded = sequence.pad_sequences(g2_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM_att.evaluate(g2_padded, y2_test)\n",
        "print(\"Group-2\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "OK5Y7rWtKjm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abba3564-50e2-4e10-9c78-42b36b676308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2395 - accuracy: 0.9010 - get_f1: 0.0176 - get_recall: 0.0089 - get_precision: 0.9137\n",
            "Group-2\n",
            "Loss: 0.23947228491306305\n",
            "Accuracy: 0.9009777903556824\n",
            "Recall: 0.008875997737050056\n",
            "Precision: 0.9137227535247803\n",
            "F1-score: 0.01757892780005932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-3\n",
        "\n",
        "g3_test = tokenizer.texts_to_sequences(x3_test)\n",
        "g3_padded = sequence.pad_sequences(g3_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM_att.evaluate(g3_padded, y3_test)\n",
        "print(\"Group-3\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "mAKvZRKoKjm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d952dc0-ea29-44f1-8109-8136f2231a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1783 - accuracy: 0.9333 - get_f1: 0.0186 - get_recall: 0.0094 - get_precision: 0.9294\n",
            "Group-3\n",
            "Loss: 0.17825758457183838\n",
            "Accuracy: 0.9333111047744751\n",
            "Recall: 0.009391783736646175\n",
            "Precision: 0.9294322729110718\n",
            "F1-score: 0.018593842163681984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-4\n",
        "\n",
        "g4_test = tokenizer.texts_to_sequences(x4_test)\n",
        "g4_padded = sequence.pad_sequences(g4_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM_att.evaluate(g4_padded, y4_test)\n",
        "print(\"Group-4\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "yjdM2j2MKjm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78869e0-9899-4201-bc66-852a40ead7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1733 - accuracy: 0.9354 - get_f1: 0.0187 - get_recall: 0.0094 - get_precision: 0.9296\n",
            "Group-4\n",
            "Loss: 0.1733327955007553\n",
            "Accuracy: 0.9354000091552734\n",
            "Recall: 0.009432525373995304\n",
            "Precision: 0.9296061396598816\n",
            "F1-score: 0.018673818558454514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-5\n",
        "\n",
        "g5_test = tokenizer.texts_to_sequences(x5_test)\n",
        "g5_padded = sequence.pad_sequences(g5_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = LSTM_att.evaluate(g5_padded, y5_test)\n",
        "print(\"Group-5\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "wIsOGbblKjm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cd0c82-c588-4f95-bced-d519761e5ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1725 - accuracy: 0.9373 - get_f1: 0.0187 - get_recall: 0.0095 - get_precision: 0.9320\n",
            "Group-5\n",
            "Loss: 0.17248670756816864\n",
            "Accuracy: 0.9373111128807068\n",
            "Recall: 0.009453484788537025\n",
            "Precision: 0.9320306181907654\n",
            "F1-score: 0.018715348094701767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi-LSTM"
      ],
      "metadata": {
        "id": "miBjM9hwTwcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "BcS7YMhHfAQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    'num_lstm_layers': [1, 2, 3],\n",
        "    'num_lstm_units': [32, 64, 128],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4]\n",
        "}\n",
        "\n",
        "param_grid = list(ParameterGrid(hyperparameters))"
      ],
      "metadata": {
        "id": "MiykwA2gTxAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_lstm_layers, num_lstm_units, learning_rate, dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000, 128, input_length=max_len))\n",
        "    model.add(Bidirectional(LSTM(num_lstm_units, return_sequences=True)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "ds05CwaXfDm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search\n",
        "best_params = None\n",
        "best_score = 0\n",
        "for params in param_grid:\n",
        "    model = create_model(**params)\n",
        "    model.fit(train_padded, y_train,batch_size=128,epochs=10, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=10)],steps_per_epoch=2048)\n",
        "    loss, score = model.evaluate(test_padded, y_test)\n",
        "    print(f\"params: {params}, score: {score}\")\n",
        "\n",
        "    # Save best hyperparameters\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_params = params"
      ],
      "metadata": {
        "id": "3AR0WaB0fQcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "yozz4EHdfTRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bi_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000, 128, input_length=max_len))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "niUfdJIWfTK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model on combined training and validation set with best hyperparameters\n",
        "final_model = bi_lstm_model()\n",
        "final_model.summary()\n",
        "final_model.fit(train_padded, y_train ,batch_size=128,epochs=1000, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=15)],steps_per_epoch=2048)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkV9Kwn8flRO",
        "outputId": "1cb1abb9-980a-426a-ca6d-aebda3bf255c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 100, 128)          2560000   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 100, 256)         263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 100, 256)          0         \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 100, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 100, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 100, 256)          0         \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 100, 256)          0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 100, 1)            257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,217,665\n",
            "Trainable params: 3,217,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "2048/2048 [==============================] - 146s 68ms/step - loss: 0.3522 - accuracy: 0.8457 - val_loss: 0.3031 - val_accuracy: 0.8718\n",
            "Epoch 2/1000\n",
            "2048/2048 [==============================] - 104s 51ms/step - loss: 0.2890 - accuracy: 0.8774 - val_loss: 0.2718 - val_accuracy: 0.8824\n",
            "Epoch 3/1000\n",
            "2048/2048 [==============================] - 100s 49ms/step - loss: 0.2631 - accuracy: 0.8893 - val_loss: 0.2701 - val_accuracy: 0.8878\n",
            "Epoch 4/1000\n",
            "2048/2048 [==============================] - 99s 49ms/step - loss: 0.2472 - accuracy: 0.8971 - val_loss: 0.2388 - val_accuracy: 0.9007\n",
            "Epoch 5/1000\n",
            "2048/2048 [==============================] - 99s 48ms/step - loss: 0.2382 - accuracy: 0.9014 - val_loss: 0.2349 - val_accuracy: 0.9025\n",
            "Epoch 6/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2312 - accuracy: 0.9043 - val_loss: 0.2271 - val_accuracy: 0.9056\n",
            "Epoch 7/1000\n",
            "2048/2048 [==============================] - 99s 48ms/step - loss: 0.2258 - accuracy: 0.9062 - val_loss: 0.2217 - val_accuracy: 0.9081\n",
            "Epoch 8/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2161 - accuracy: 0.9112 - val_loss: 0.2223 - val_accuracy: 0.9087\n",
            "Epoch 9/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2082 - accuracy: 0.9153 - val_loss: 0.2271 - val_accuracy: 0.9076\n",
            "Epoch 10/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2090 - accuracy: 0.9148 - val_loss: 0.2183 - val_accuracy: 0.9105\n",
            "Epoch 11/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2057 - accuracy: 0.9166 - val_loss: 0.2138 - val_accuracy: 0.9120\n",
            "Epoch 12/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2053 - accuracy: 0.9159 - val_loss: 0.2132 - val_accuracy: 0.9115\n",
            "Epoch 13/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2021 - accuracy: 0.9178 - val_loss: 0.2103 - val_accuracy: 0.9136\n",
            "Epoch 14/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2020 - accuracy: 0.9180 - val_loss: 0.2070 - val_accuracy: 0.9153\n",
            "Epoch 15/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.2000 - accuracy: 0.9187 - val_loss: 0.2073 - val_accuracy: 0.9152\n",
            "Epoch 16/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1851 - accuracy: 0.9255 - val_loss: 0.2095 - val_accuracy: 0.9147\n",
            "Epoch 17/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1809 - accuracy: 0.9276 - val_loss: 0.2053 - val_accuracy: 0.9163\n",
            "Epoch 18/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1830 - accuracy: 0.9263 - val_loss: 0.2072 - val_accuracy: 0.9150\n",
            "Epoch 19/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1842 - accuracy: 0.9259 - val_loss: 0.2055 - val_accuracy: 0.9166\n",
            "Epoch 20/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1860 - accuracy: 0.9247 - val_loss: 0.2039 - val_accuracy: 0.9165\n",
            "Epoch 21/1000\n",
            "2048/2048 [==============================] - 99s 48ms/step - loss: 0.1844 - accuracy: 0.9259 - val_loss: 0.2029 - val_accuracy: 0.9172\n",
            "Epoch 22/1000\n",
            "2048/2048 [==============================] - 99s 48ms/step - loss: 0.1863 - accuracy: 0.9246 - val_loss: 0.2054 - val_accuracy: 0.9177\n",
            "Epoch 23/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1824 - accuracy: 0.9261 - val_loss: 0.2099 - val_accuracy: 0.9167\n",
            "Epoch 24/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1617 - accuracy: 0.9360 - val_loss: 0.2076 - val_accuracy: 0.9165\n",
            "Epoch 25/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1655 - accuracy: 0.9346 - val_loss: 0.2066 - val_accuracy: 0.9172\n",
            "Epoch 26/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1674 - accuracy: 0.9335 - val_loss: 0.2047 - val_accuracy: 0.9174\n",
            "Epoch 27/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1672 - accuracy: 0.9332 - val_loss: 0.2048 - val_accuracy: 0.9170\n",
            "Epoch 28/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1700 - accuracy: 0.9312 - val_loss: 0.2058 - val_accuracy: 0.9174\n",
            "Epoch 29/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1703 - accuracy: 0.9318 - val_loss: 0.2052 - val_accuracy: 0.9175\n",
            "Epoch 30/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1697 - accuracy: 0.9321 - val_loss: 0.2032 - val_accuracy: 0.9180\n",
            "Epoch 31/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1584 - accuracy: 0.9374 - val_loss: 0.2167 - val_accuracy: 0.9166\n",
            "Epoch 32/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1463 - accuracy: 0.9426 - val_loss: 0.2125 - val_accuracy: 0.9160\n",
            "Epoch 33/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1492 - accuracy: 0.9412 - val_loss: 0.2143 - val_accuracy: 0.9168\n",
            "Epoch 34/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1522 - accuracy: 0.9401 - val_loss: 0.2144 - val_accuracy: 0.9172\n",
            "Epoch 35/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1543 - accuracy: 0.9387 - val_loss: 0.2096 - val_accuracy: 0.9164\n",
            "Epoch 36/1000\n",
            "2048/2048 [==============================] - 98s 48ms/step - loss: 0.1550 - accuracy: 0.9389 - val_loss: 0.2113 - val_accuracy: 0.9164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f747c6bf550>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate final model on test set\n",
        "loss, best_score = model.evaluate(test_padded, y_test)\n",
        "print(f\"Validation accuracy: {best_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htFJlZtYgn-C",
        "outputId": "ae834256-2a5a-47d5-e9a0-f96433960cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7813/7813 [==============================] - 67s 9ms/step - loss: 0.2043 - accuracy: 0.9165\n",
            "Validation accuracy: 0.9165172576904297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "F5I_yj5thAsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save('Bi-LSTM.h5')"
      ],
      "metadata": {
        "id": "elnwzHthg6g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model and test for each group"
      ],
      "metadata": {
        "id": "qZ2C9Ep8g_gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100\n",
        "Bi_LSTM = load_model('/content/drive/MyDrive/NLP/Bi-LSTM.h5')\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "Bi_LSTM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', get_f1, get_recall, get_precision])\n",
        "bi_lstm = []"
      ],
      "metadata": {
        "id": "Y7gxuy0Ig_gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-1\n",
        "\n",
        "g1_test = tokenizer.texts_to_sequences(x1_test)\n",
        "g1_padded = sequence.pad_sequences(g1_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM.evaluate(g1_padded, y1_test)\n",
        "print(\"Group-1\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "bi_lstm.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPkbkq8C0bbR",
        "outputId": "206e8154-9663-400f-b598-dbded8c9277d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 15s 9ms/step - loss: 0.2867 - accuracy: 0.8764 - get_f1: 1.7509 - get_recall: 86.7592 - get_precision: 0.8845\n",
            "Group-1\n",
            "Loss: 0.28673017024993896\n",
            "Accuracy: 0.8763548731803894\n",
            "Recall: 86.75917053222656\n",
            "Precision: 0.8844908475875854\n",
            "F1-score: 1.7508546113967896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-2\n",
        "\n",
        "g2_test = tokenizer.texts_to_sequences(x2_test)\n",
        "g2_padded = sequence.pad_sequences(g2_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM.evaluate(g2_padded, y2_test)\n",
        "print(\"Group-2\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "bi_lstm.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab072cf4-d1c7-473d-8a90-8ebf9a256831",
        "id": "-SP1soOBg_gm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.2323 - accuracy: 0.9011 - get_f1: 1.7991 - get_recall: 89.2928 - get_precision: 0.9088\n",
            "Group-2\n",
            "Loss: 0.23233242332935333\n",
            "Accuracy: 0.9010528922080994\n",
            "Recall: 89.29283905029297\n",
            "Precision: 0.9088422656059265\n",
            "F1-score: 1.799122929573059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-3\n",
        "\n",
        "g3_test = tokenizer.texts_to_sequences(x3_test)\n",
        "g3_padded = sequence.pad_sequences(g3_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM.evaluate(g3_padded, y3_test)\n",
        "print(\"Group-3\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "bi_lstm.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05bc2ef-4781-4c75-bb3f-a05d447b9db0",
        "id": "7fm59Lvxg_gn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.1725 - accuracy: 0.9336 - get_f1: 1.8485 - get_recall: 93.4625 - get_precision: 0.9336\n",
            "Group-3\n",
            "Loss: 0.17250226438045502\n",
            "Accuracy: 0.9336283206939697\n",
            "Recall: 93.46250915527344\n",
            "Precision: 0.9335668683052063\n",
            "F1-score: 1.8485151529312134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-4\n",
        "\n",
        "g4_test = tokenizer.texts_to_sequences(x4_test)\n",
        "g4_padded = sequence.pad_sequences(g4_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM.evaluate(g4_padded, y4_test)\n",
        "print(\"Group-4\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "bi_lstm.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0b797d-bb91-41ba-83c3-f894f1e33981",
        "id": "UiXh06ipg_gn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1654 - accuracy: 0.9349 - get_f1: 1.8545 - get_recall: 93.3763 - get_precision: 0.9366\n",
            "Group-4\n",
            "Loss: 0.16543422639369965\n",
            "Accuracy: 0.9349337816238403\n",
            "Recall: 93.37626647949219\n",
            "Precision: 0.9366396069526672\n",
            "F1-score: 1.854522943496704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-5\n",
        "\n",
        "g5_test = tokenizer.texts_to_sequences(x5_test)\n",
        "g5_padded = sequence.pad_sequences(g5_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM.evaluate(g5_padded, y5_test)\n",
        "print(\"Group-5\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "bi_lstm.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38cb2a9-f66e-47f6-fc31-53509aad7aaa",
        "id": "CGJ9fH-Tg_gn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.1641 - accuracy: 0.9361 - get_f1: 1.8601 - get_recall: 93.3668 - get_precision: 0.9395\n",
            "Group-5\n",
            "Loss: 0.16411162912845612\n",
            "Accuracy: 0.9360813498497009\n",
            "Recall: 93.36680603027344\n",
            "Precision: 0.9394614696502686\n",
            "F1-score: 1.860052466392517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi-LSTM with Attention"
      ],
      "metadata": {
        "id": "Kw_R1g29Ba_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "FDZrJuexY_3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    'num_lstm_layers': [1, 2, 3],\n",
        "    'num_lstm_units': [32, 64, 128],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4]\n",
        "}\n",
        "\n",
        "param_grid = list(ParameterGrid(hyperparameters))"
      ],
      "metadata": {
        "id": "cBpOlkscY_3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(Attention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self,  features, hidden, mask=None):\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "    score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "    if mask is not None:\n",
        "      attention_weights *= mask\n",
        "      attention_weights = tf.nn.softmax(attention_weights, axis=1)\n",
        "    context_vector = attention_weights * features\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "  def compute_output_shape(self,input_shape):\n",
        "    return (input_shape[0],input_shape[-1])\n",
        "\n",
        "  def get_config(self):\n",
        "    return super(Attention,self).get_config()"
      ],
      "metadata": {
        "id": "kzXeLa5EY_3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(max_len, num_lstm_layers, num_lstm_units, num_dense_units, learning_rate, dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(20000, 128, input_length=max_len))\n",
        "    for i in range(num_lstm_layers):\n",
        "        model.add(Bidirectional(LSTM(num_lstm_units, return_sequences=True)))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(attention(max_len))\n",
        "    model.add(Dense(num_dense_units, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "rAylPCKSY_3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform grid search\n",
        "best_params = None\n",
        "best_score = 0\n",
        "for params in param_grid:\n",
        "    model = create_model(**params)\n",
        "    model.fit(train_padded, y_train,batch_size=128,epochs=10, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=10)],steps_per_epoch=2048)\n",
        "    loss, score = model.evaluate(test_padded, y_test)\n",
        "    print(f\"params: {params}, score: {score}\")\n",
        "\n",
        "    # Save best hyperparameters\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_params = params"
      ],
      "metadata": {
        "id": "QfuIdCJiY_3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "_WV2BGr7Y_3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bi_lstm_attention_model():\n",
        "  sequence_input = Input(shape=(max_len,), dtype=\"int32\")\n",
        "  embedded_sequences = Embedding(max_word, 128)(sequence_input)\n",
        "\n",
        "  # First Bidirectional LSTM layer\n",
        "  lstm_1 = Bidirectional(LSTM(128, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(embedded_sequences)\n",
        "  (forward_h1, forward_c1, backward_h1, backward_c1) = lstm_1[1:]\n",
        "\n",
        "  # Second Bidirectional LSTM layer\n",
        "  lstm_2 = Bidirectional(LSTM(128, return_sequences=True, return_state=True), name=\"bi_lstm_2\")(lstm_1[0])\n",
        "  (forward_h2, forward_c2, backward_h2, backward_c2) = lstm_2[1:]\n",
        "\n",
        "  # Concatenate forward and backward hidden states\n",
        "  state_h = Concatenate()([forward_h2, backward_h2])\n",
        "  state_c = Concatenate()([forward_c2, backward_c2])\n",
        "\n",
        "  # Attention mechanism\n",
        "  context_vector, attention_weights = Attention(128)(lstm_2[0], state_h)\n",
        "\n",
        "  # Dense layers\n",
        "  dense1 = Dense(128, activation=\"relu\")(context_vector)\n",
        "  dropout = Dropout(0.2)(dense1)\n",
        "  output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "\n",
        "  model = tf.keras.Model(inputs=sequence_input, outputs=output)\n",
        "  optimizer = Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', get_f1, get_recall, get_precision])\n",
        "  return model"
      ],
      "metadata": {
        "id": "26lGdN-eY_3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = bi_lstm_attention_model()\n",
        "model.summary()\n",
        "model.fit(train_padded, y_train ,batch_size=128,epochs=1000, validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=15)],steps_per_epoch=2048)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0478ef52-9473-4e50-8ac9-657662cf64cf",
        "id": "wxwtSlbjY_3Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 100, 128)     2560000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bi_lstm_1 (Bidirectional)      [(None, 100, 256),   263168      ['embedding_1[0][0]']            \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " bi_lstm_2 (Bidirectional)      [(None, 100, 256),   394240      ['bi_lstm_1[0][0]']              \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256)          0           ['bi_lstm_2[0][1]',              \n",
            "                                                                  'bi_lstm_2[0][3]']              \n",
            "                                                                                                  \n",
            " attention_1 (Attention)        ((None, 256),        65921       ['bi_lstm_2[0][0]',              \n",
            "                                 (None, 100, 1))                  'concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          32896       ['attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            129         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,316,354\n",
            "Trainable params: 3,316,354\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "2048/2048 [==============================] - 168s 78ms/step - loss: 0.3224 - accuracy: 0.8575 - get_f1: 0.8511 - get_recall: 0.8431 - get_precision: 0.8651 - val_loss: 0.2720 - val_accuracy: 0.8851 - val_get_f1: 0.8875 - val_get_recall: 0.9069 - val_get_precision: 0.8704\n",
            "Epoch 2/1000\n",
            "2048/2048 [==============================] - 106s 52ms/step - loss: 0.2558 - accuracy: 0.8926 - get_f1: 0.8906 - get_recall: 0.8837 - get_precision: 0.8997 - val_loss: 0.2501 - val_accuracy: 0.8973 - val_get_f1: 0.8969 - val_get_recall: 0.8960 - val_get_precision: 0.8994\n",
            "Epoch 3/1000\n",
            "2048/2048 [==============================] - 105s 51ms/step - loss: 0.2418 - accuracy: 0.8994 - get_f1: 0.8974 - get_recall: 0.8895 - get_precision: 0.9072 - val_loss: 0.2337 - val_accuracy: 0.9022 - val_get_f1: 0.9026 - val_get_recall: 0.9075 - val_get_precision: 0.8992\n",
            "Epoch 4/1000\n",
            "2048/2048 [==============================] - 104s 51ms/step - loss: 0.2306 - accuracy: 0.9050 - get_f1: 0.9037 - get_recall: 0.8977 - get_precision: 0.9116 - val_loss: 0.2272 - val_accuracy: 0.9051 - val_get_f1: 0.9037 - val_get_recall: 0.8904 - val_get_precision: 0.9187\n",
            "Epoch 5/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.2230 - accuracy: 0.9082 - get_f1: 0.9069 - get_recall: 0.9006 - get_precision: 0.9148 - val_loss: 0.2200 - val_accuracy: 0.9080 - val_get_f1: 0.9072 - val_get_recall: 0.9026 - val_get_precision: 0.9134\n",
            "Epoch 6/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.2205 - accuracy: 0.9089 - get_f1: 0.9073 - get_recall: 0.8995 - get_precision: 0.9167 - val_loss: 0.2164 - val_accuracy: 0.9101 - val_get_f1: 0.9105 - val_get_recall: 0.9146 - val_get_precision: 0.9078\n",
            "Epoch 7/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.2136 - accuracy: 0.9121 - get_f1: 0.9109 - get_recall: 0.9042 - get_precision: 0.9191 - val_loss: 0.2197 - val_accuracy: 0.9094 - val_get_f1: 0.9104 - val_get_recall: 0.9242 - val_get_precision: 0.8985\n",
            "Epoch 8/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.2078 - accuracy: 0.9147 - get_f1: 0.9131 - get_recall: 0.9070 - get_precision: 0.9207 - val_loss: 0.2097 - val_accuracy: 0.9136 - val_get_f1: 0.9133 - val_get_recall: 0.9085 - val_get_precision: 0.9194\n",
            "Epoch 9/1000\n",
            "2048/2048 [==============================] - 104s 51ms/step - loss: 0.1948 - accuracy: 0.9206 - get_f1: 0.9191 - get_recall: 0.9130 - get_precision: 0.9267 - val_loss: 0.2092 - val_accuracy: 0.9142 - val_get_f1: 0.9130 - val_get_recall: 0.9027 - val_get_precision: 0.9249\n",
            "Epoch 10/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1948 - accuracy: 0.9212 - get_f1: 0.9200 - get_recall: 0.9135 - get_precision: 0.9279 - val_loss: 0.2097 - val_accuracy: 0.9147 - val_get_f1: 0.9149 - val_get_recall: 0.9169 - val_get_precision: 0.9140\n",
            "Epoch 11/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1973 - accuracy: 0.9195 - get_f1: 0.9185 - get_recall: 0.9132 - get_precision: 0.9251 - val_loss: 0.2067 - val_accuracy: 0.9153 - val_get_f1: 0.9138 - val_get_recall: 0.8990 - val_get_precision: 0.9304\n",
            "Epoch 12/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1962 - accuracy: 0.9207 - get_f1: 0.9194 - get_recall: 0.9131 - get_precision: 0.9272 - val_loss: 0.2042 - val_accuracy: 0.9166 - val_get_f1: 0.9158 - val_get_recall: 0.9075 - val_get_precision: 0.9255\n",
            "Epoch 13/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1945 - accuracy: 0.9208 - get_f1: 0.9196 - get_recall: 0.9136 - get_precision: 0.9269 - val_loss: 0.2026 - val_accuracy: 0.9172 - val_get_f1: 0.9175 - val_get_recall: 0.9198 - val_get_precision: 0.9163\n",
            "Epoch 14/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1924 - accuracy: 0.9216 - get_f1: 0.9199 - get_recall: 0.9134 - get_precision: 0.9278 - val_loss: 0.2000 - val_accuracy: 0.9181 - val_get_f1: 0.9173 - val_get_recall: 0.9108 - val_get_precision: 0.9251\n",
            "Epoch 15/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1929 - accuracy: 0.9217 - get_f1: 0.9206 - get_recall: 0.9143 - get_precision: 0.9282 - val_loss: 0.2002 - val_accuracy: 0.9189 - val_get_f1: 0.9195 - val_get_recall: 0.9240 - val_get_precision: 0.9161\n",
            "Epoch 16/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1795 - accuracy: 0.9280 - get_f1: 0.9269 - get_recall: 0.9212 - get_precision: 0.9338 - val_loss: 0.2031 - val_accuracy: 0.9174 - val_get_f1: 0.9160 - val_get_recall: 0.9018 - val_get_precision: 0.9320\n",
            "Epoch 17/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1691 - accuracy: 0.9328 - get_f1: 0.9318 - get_recall: 0.9265 - get_precision: 0.9383 - val_loss: 0.2020 - val_accuracy: 0.9167 - val_get_f1: 0.9146 - val_get_recall: 0.8945 - val_get_precision: 0.9371\n",
            "Epoch 18/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1724 - accuracy: 0.9315 - get_f1: 0.9304 - get_recall: 0.9253 - get_precision: 0.9369 - val_loss: 0.2021 - val_accuracy: 0.9184 - val_get_f1: 0.9184 - val_get_recall: 0.9167 - val_get_precision: 0.9213\n",
            "Epoch 19/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1758 - accuracy: 0.9297 - get_f1: 0.9286 - get_recall: 0.9227 - get_precision: 0.9357 - val_loss: 0.1989 - val_accuracy: 0.9188 - val_get_f1: 0.9175 - val_get_recall: 0.9050 - val_get_precision: 0.9316\n",
            "Epoch 20/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1749 - accuracy: 0.9297 - get_f1: 0.9288 - get_recall: 0.9233 - get_precision: 0.9354 - val_loss: 0.1985 - val_accuracy: 0.9194 - val_get_f1: 0.9184 - val_get_recall: 0.9062 - val_get_precision: 0.9321\n",
            "Epoch 21/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1752 - accuracy: 0.9296 - get_f1: 0.9282 - get_recall: 0.9218 - get_precision: 0.9358 - val_loss: 0.1998 - val_accuracy: 0.9183 - val_get_f1: 0.9163 - val_get_recall: 0.8962 - val_get_precision: 0.9386\n",
            "Epoch 22/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1766 - accuracy: 0.9290 - get_f1: 0.9280 - get_recall: 0.9219 - get_precision: 0.9353 - val_loss: 0.1989 - val_accuracy: 0.9187 - val_get_f1: 0.9184 - val_get_recall: 0.9186 - val_get_precision: 0.9196\n",
            "Epoch 23/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1762 - accuracy: 0.9292 - get_f1: 0.9281 - get_recall: 0.9228 - get_precision: 0.9347 - val_loss: 0.1954 - val_accuracy: 0.9201 - val_get_f1: 0.9195 - val_get_recall: 0.9156 - val_get_precision: 0.9248\n",
            "Epoch 24/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1540 - accuracy: 0.9392 - get_f1: 0.9385 - get_recall: 0.9348 - get_precision: 0.9433 - val_loss: 0.2062 - val_accuracy: 0.9184 - val_get_f1: 0.9177 - val_get_recall: 0.9085 - val_get_precision: 0.9283\n",
            "Epoch 25/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1511 - accuracy: 0.9407 - get_f1: 0.9397 - get_recall: 0.9355 - get_precision: 0.9448 - val_loss: 0.2056 - val_accuracy: 0.9186 - val_get_f1: 0.9178 - val_get_recall: 0.9097 - val_get_precision: 0.9273\n",
            "Epoch 26/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1548 - accuracy: 0.9389 - get_f1: 0.9381 - get_recall: 0.9331 - get_precision: 0.9441 - val_loss: 0.2048 - val_accuracy: 0.9189 - val_get_f1: 0.9174 - val_get_recall: 0.9037 - val_get_precision: 0.9330\n",
            "Epoch 27/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1557 - accuracy: 0.9382 - get_f1: 0.9375 - get_recall: 0.9327 - get_precision: 0.9434 - val_loss: 0.1990 - val_accuracy: 0.9198 - val_get_f1: 0.9192 - val_get_recall: 0.9137 - val_get_precision: 0.9261\n",
            "Epoch 28/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1587 - accuracy: 0.9371 - get_f1: 0.9363 - get_recall: 0.9313 - get_precision: 0.9423 - val_loss: 0.2014 - val_accuracy: 0.9197 - val_get_f1: 0.9186 - val_get_recall: 0.9078 - val_get_precision: 0.9310\n",
            "Epoch 29/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1609 - accuracy: 0.9362 - get_f1: 0.9352 - get_recall: 0.9301 - get_precision: 0.9414 - val_loss: 0.2007 - val_accuracy: 0.9195 - val_get_f1: 0.9185 - val_get_recall: 0.9081 - val_get_precision: 0.9304\n",
            "Epoch 30/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1617 - accuracy: 0.9357 - get_f1: 0.9348 - get_recall: 0.9300 - get_precision: 0.9408 - val_loss: 0.1985 - val_accuracy: 0.9199 - val_get_f1: 0.9194 - val_get_recall: 0.9141 - val_get_precision: 0.9259\n",
            "Epoch 31/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1568 - accuracy: 0.9378 - get_f1: 0.9370 - get_recall: 0.9326 - get_precision: 0.9423 - val_loss: 0.2221 - val_accuracy: 0.9182 - val_get_f1: 0.9184 - val_get_recall: 0.9231 - val_get_precision: 0.9150\n",
            "Epoch 32/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1301 - accuracy: 0.9498 - get_f1: 0.9492 - get_recall: 0.9457 - get_precision: 0.9536 - val_loss: 0.2182 - val_accuracy: 0.9190 - val_get_f1: 0.9185 - val_get_recall: 0.9118 - val_get_precision: 0.9264\n",
            "Epoch 33/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1344 - accuracy: 0.9476 - get_f1: 0.9470 - get_recall: 0.9429 - get_precision: 0.9521 - val_loss: 0.2216 - val_accuracy: 0.9179 - val_get_f1: 0.9174 - val_get_recall: 0.9118 - val_get_precision: 0.9242\n",
            "Epoch 34/1000\n",
            "2048/2048 [==============================] - 103s 50ms/step - loss: 0.1380 - accuracy: 0.9458 - get_f1: 0.9449 - get_recall: 0.9401 - get_precision: 0.9507 - val_loss: 0.2118 - val_accuracy: 0.9179 - val_get_f1: 0.9174 - val_get_recall: 0.9126 - val_get_precision: 0.9235\n",
            "Epoch 35/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1394 - accuracy: 0.9455 - get_f1: 0.9448 - get_recall: 0.9409 - get_precision: 0.9497 - val_loss: 0.2164 - val_accuracy: 0.9180 - val_get_f1: 0.9180 - val_get_recall: 0.9179 - val_get_precision: 0.9193\n",
            "Epoch 36/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1450 - accuracy: 0.9432 - get_f1: 0.9426 - get_recall: 0.9387 - get_precision: 0.9474 - val_loss: 0.2096 - val_accuracy: 0.9183 - val_get_f1: 0.9178 - val_get_recall: 0.9118 - val_get_precision: 0.9250\n",
            "Epoch 37/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1432 - accuracy: 0.9440 - get_f1: 0.9432 - get_recall: 0.9387 - get_precision: 0.9487 - val_loss: 0.2066 - val_accuracy: 0.9185 - val_get_f1: 0.9182 - val_get_recall: 0.9144 - val_get_precision: 0.9233\n",
            "Epoch 38/1000\n",
            "2048/2048 [==============================] - 102s 50ms/step - loss: 0.1459 - accuracy: 0.9426 - get_f1: 0.9419 - get_recall: 0.9383 - get_precision: 0.9464 - val_loss: 0.2089 - val_accuracy: 0.9188 - val_get_f1: 0.9187 - val_get_recall: 0.9190 - val_get_precision: 0.9197\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ed04656a0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate final model on test set\n",
        "loss, best_score, f1, recall, precision= model.evaluate(test_padded, y_test)\n",
        "print(f\"Validation accuracy: {best_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxMf6IoWY_3Q",
        "outputId": "db201e42-a834-42d0-cebf-356e053ad987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7032/7032 [==============================] - 68s 10ms/step - loss: 0.2089 - accuracy: 0.9188 - get_f1: 0.9168 - get_recall: 0.9188 - get_precision: 0.9197\n",
            "Validation accuracy: 0.9188133478164673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ],
      "metadata": {
        "id": "ddjUanaBY_3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('Bi-LSTM_att_weights.h5')"
      ],
      "metadata": {
        "id": "VPFUD9sBY_3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model and test for each group"
      ],
      "metadata": {
        "id": "oir7_BSXY_3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Bi_LSTM_Att = []\n",
        "Bi_LSTM_att = bi_lstm_attention_model()\n",
        "Bi_LSTM_att.load_weights(\"/content/drive/MyDrive/NLP/Bi-LSTM_att_weights.h5\")"
      ],
      "metadata": {
        "id": "JPTP-UhdY_3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "cb24e471-9c28-41d6-b9da-85a5c5dd9bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-1acccb792a38>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBi_LSTM_Att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mBi_LSTM_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbi_lstm_attention_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mBi_LSTM_att\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/NLP/Bi-LSTM_att_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-d929a787dabd>\u001b[0m in \u001b[0;36mbi_lstm_attention_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# First Bidirectional LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mlstm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bi_lstm_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mforward_h1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_c1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_h1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_c1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'return_state'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-1\n",
        "\n",
        "g1_test = tokenizer.texts_to_sequences(x1_test)\n",
        "g1_padded = sequence.pad_sequences(g1_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM_att.evaluate(g1_padded, y1_test)\n",
        "print(\"Group-1\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "Bi_LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "BNKK_PGadwBS",
        "outputId": "9b3876e9-98c4-4930-ffea-827ddbe9e2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-7e5373f7fdeb>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg1_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBi_LSTM_att\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Group-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Bi_LSTM_att' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-2\n",
        "\n",
        "g2_test = tokenizer.texts_to_sequences(x2_test)\n",
        "g2_padded = sequence.pad_sequences(g2_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM_att.evaluate(g2_padded, y2_test)\n",
        "print(\"Group-2\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "Bi_LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "S7DP1RHsY_3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-3\n",
        "\n",
        "g3_test = tokenizer.texts_to_sequences(x3_test)\n",
        "g3_padded = sequence.pad_sequences(g3_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM_att.evaluate(g3_padded, y3_test)\n",
        "print(\"Group-3\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "Bi_LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "SQ9LB4OmY_3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-4\n",
        "\n",
        "g4_test = tokenizer.texts_to_sequences(x4_test)\n",
        "g4_padded = sequence.pad_sequences(g4_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM_att.evaluate(g4_padded, y4_test)\n",
        "print(\"Group-4\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "Bi_LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "k9aNRYMGY_3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-5\n",
        "\n",
        "g5_test = tokenizer.texts_to_sequences(x5_test)\n",
        "g5_padded = sequence.pad_sequences(g5_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy, f1, recall, precision = Bi_LSTM_att.evaluate(g5_padded, y5_test)\n",
        "print(\"Group-5\")\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "Bi_LSTM_Att.append(accuracy)"
      ],
      "metadata": {
        "id": "SqJJqDaRY_3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers"
      ],
      "metadata": {
        "id": "gp0qK1vcyOaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads,\n",
        "                                             key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)  # self-attention layer\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)  # layer norm\n",
        "        ffn_output = self.ffn(out1)  #feed-forward layer\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)  # layer norm\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size,\n",
        "                                          output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "A1Gp6mmxyQU6",
        "outputId": "e97b7336-6c6d-411b-e3e5-96a3ab376ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f4b0f73ac868>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTransformerBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         self.att = layers.MultiHeadAttention(num_heads=num_heads,\n\u001b[1;32m      5\u001b[0m                                              key_dim=embed_dim)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  embed_dim = 128  # Embedding size for each token\n",
        "  num_heads = 8  # Number of attention heads\n",
        "  ff_dim = 8  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "  ## Using Sequential API\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Input(shape=(max_len, )))\n",
        "  model.add(TokenAndPositionEmbedding(max_len, 20000, embed_dim))\n",
        "  model.add(TransformerBlock(embed_dim, num_heads, ff_dim))\n",
        "  model.add(layers.GlobalAveragePooling1D())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(ff_dim, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "0VZL74BPzP53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans = create_model()\n",
        "trans.summary()\n",
        "trans.compile(loss='binary_crossentropy',optimizer=Adamax(.01),metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwaNgE81zQl4",
        "outputId": "2cf4ba84-3a8b-495e-a1a0-6867e5214fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " token_and_position_embeddin  (None, 100, 128)         2572800   \n",
            " g_8 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_block_8 (Transf  (None, 100, 128)         530184    \n",
            " ormerBlock)                                                     \n",
            "                                                                 \n",
            " global_average_pooling1d_8   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,104,025\n",
            "Trainable params: 3,104,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=trans.fit(train_padded,y_train,batch_size=128,epochs=50,validation_data=(test_padded,y_test),callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.00001,patience=5)],steps_per_epoch=2048)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "Bjkx9iStzTJo",
        "outputId": "e661ef68-f4a4-483d-fa8a-fed0a5719c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21ba001ee4f7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_padded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trans' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model and test for each group"
      ],
      "metadata": {
        "id": "WlwxtJRuzg_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = []"
      ],
      "metadata": {
        "id": "NL-QTu-zA_1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_old = []"
      ],
      "metadata": {
        "id": "Xx2oB3QvC0nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-1\n",
        "\n",
        "g1_test = tokenizer.texts_to_sequences(x1_test)\n",
        "g1_padded = sequence.pad_sequences(g1_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy = trans.evaluate(g1_padded, y1_test)\n",
        "print(\"Group-1\")\n",
        "print(f\"Loss(%): {loss*100}\")\n",
        "print(f\"Accuracy(%): {accuracy*100}\")\n",
        "transformer_old.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4f7677-1591-4e97-c3d4-d938f64ce6cd",
        "id": "Y9eTxLCczg_Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4127 - accuracy: 0.8094\n",
            "Group-1\n",
            "Loss(%): 41.27286076545715\n",
            "Accuracy(%): 80.94000220298767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-2\n",
        "\n",
        "g2_test = tokenizer.texts_to_sequences(x2_test)\n",
        "g2_padded = sequence.pad_sequences(g2_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy = trans.evaluate(g2_padded, y2_test)\n",
        "print(\"Group-2\")\n",
        "print(f\"Loss(%): {loss*100}\")\n",
        "print(f\"Accuracy(%): {accuracy*100}\")\n",
        "transformer_old.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d35c4b7-f9af-4619-8b4d-d9d468540bc2",
        "id": "O1xgbe9azg_Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3366 - accuracy: 0.8482\n",
            "Group-2\n",
            "Loss(%): 33.65573585033417\n",
            "Accuracy(%): 84.82000231742859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-3\n",
        "\n",
        "g3_test = tokenizer.texts_to_sequences(x3_test)\n",
        "g3_padded = sequence.pad_sequences(g3_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy = trans.evaluate(g3_padded, y3_test)\n",
        "print(\"Group-3\")\n",
        "print(f\"Loss(%): {loss*100}\")\n",
        "print(f\"Accuracy(%): {accuracy*100}\")\n",
        "transformer_old.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa54d87a-4372-4594-cabe-a9707a42ec78",
        "id": "h_qRreqpzg_a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2534 - accuracy: 0.8957\n",
            "Group-3\n",
            "Loss(%): 25.343382358551025\n",
            "Accuracy(%): 89.56500291824341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-4\n",
        "\n",
        "g4_test = tokenizer.texts_to_sequences(x4_test)\n",
        "g4_padded = sequence.pad_sequences(g4_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy = trans.evaluate(g4_padded, y4_test)\n",
        "print(\"Group-4\")\n",
        "print(f\"Loss(%): {loss*100}\")\n",
        "print(f\"Accuracy(%): {accuracy*100}\")\n",
        "transformer_old.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9230abe3-08ba-455a-8806-559872f764cf",
        "id": "xFj7ImEdzg_a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2633 - accuracy: 0.8911\n",
            "Group-4\n",
            "Loss(%): 26.3296902179718\n",
            "Accuracy(%): 89.11499977111816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group-5\n",
        "\n",
        "g5_test = tokenizer.texts_to_sequences(x5_test)\n",
        "g5_padded = sequence.pad_sequences(g5_test, padding='post', maxlen=max_len)\n",
        "loss, accuracy = trans.evaluate(g5_padded, y5_test)\n",
        "print(\"Group-5\")\n",
        "print(f\"Loss(%): {loss*100}\")\n",
        "print(f\"Accuracy(%): {accuracy*100}\")\n",
        "transformer_old.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb74287-2bb8-4494-f9b3-83b3ab20500d",
        "id": "HxwHsXwmzg_b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2732 - accuracy: 0.8874\n",
            "Group-5\n",
            "Loss(%): 27.32294797897339\n",
            "Accuracy(%): 88.74499797821045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs"
      ],
      "metadata": {
        "id": "OHg5MEXr5lmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_original = [0.8732087016105652,\n",
        " 0.889759361743927,\n",
        " 0.9111257195472717,\n",
        " 0.9032427668571472,\n",
        " 0.8985908627510071]"
      ],
      "metadata": {
        "id": "GnM5BntD5lCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_Att = [0.8747110962867737,\n",
        " 0.9009777903556824,\n",
        " 0.9333111047744751,\n",
        " 0.9354000091552734,\n",
        " 0.9373111128807068]"
      ],
      "metadata": {
        "id": "KK05MgHS5o-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bi_lstm = [0.8763548731803894,\n",
        " 0.9010528922080994,\n",
        " 0.9336283206939697,\n",
        " 0.9349337816238403,\n",
        " 0.9360813498497009]"
      ],
      "metadata": {
        "id": "ASdKg0W6MjhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Bi_LSTM_Att = [0.8769333362579346,\n",
        " 0.9040666818618774,\n",
        " 0.9352889060974121,\n",
        " 0.9390666484832764,\n",
        " 0.9387111067771912]"
      ],
      "metadata": {
        "id": "nvDg5l7AwxAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = [0.824999, 0.8241, 0.836799, 0.829649, 0.8226]"
      ],
      "metadata": {
        "id": "pAUk51XTz9B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rc('axes', titlesize=18, labelsize=18)\n",
        "plt.rc('legend', fontsize=8)\n",
        "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=10)    # fontsize of the tick labels\n",
        "plt.plot([1, 2, 3, 4, 5], Bi_LSTM_Att, label = 'Bi-LSTM - With Attention')\n",
        "plt.plot([1, 2, 3, 4, 5], LSTM_Att, label = 'LSTM - With Attention')\n",
        "plt.plot([1, 2, 3, 4, 5], bi_lstm, label = 'Bi-LSTM')\n",
        "plt.plot([1, 2, 3, 4, 5], LSTM_original[0:5], label = 'LSTM')\n",
        "plt.plot([1, 2, 3, 4, 5], transformer, label = 'Transformer')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Sequence Length Groups\")\n",
        "plt.xticks(np.arange(0, 5.1, 1.0))\n",
        "plt.xlim(1,5.1)\n",
        "plt.ylim(0.8, 1)\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "v8hdIH3f5qXx",
        "outputId": "375c4f00-76f6-4ade-8f01-ad38936291de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4f3bc9b400>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group - 1 Calculations"
      ],
      "metadata": {
        "id": "c7xIuwt3oOhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as k\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "yXoimhJP7k8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow.keras as k\n",
        "from tensorflow.keras import backend as K\n",
        "\"\"\"\n",
        " It adds f1 score as a metric to the compiled model and compiles the model with the input weight\n",
        "\"\"\"\n",
        "\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def get_recall(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def get_precision(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return precision"
      ],
      "metadata": {
        "id": "dpR_mAuV4HaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4hNLNoL9AlP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Y2-I7PacDTzN",
        "222dug5Zl20K",
        "xT1-NL3LOxXs",
        "zZhUlMHZxiAd",
        "aiQNdXcs-0YG",
        "TplRzOGDEAri",
        "gzWqOfAfbM_m",
        "wp_F6NW9eObz",
        "tlTYv43ZwM82",
        "TeMa5FA3wUv_",
        "jfnHyOnCg3ld",
        "JjaGXgMRKjm9",
        "miBjM9hwTwcE",
        "BcS7YMhHfAQX",
        "F5I_yj5thAsX",
        "qZ2C9Ep8g_gk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}